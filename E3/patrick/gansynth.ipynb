{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GANSynth - Síntese de timbres musicais\n",
    "\n",
    "### Alunos: Gabriel, Gleyson, Patrick\n",
    "\n",
    "O objetivo deste trabalho foi a reprodução do modelo GANSynth, cuja\n",
    "arquitetura consiste em um gerador e um discriminador convolucionais e cujo\n",
    "objetivo era a síntese musical.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "O primeiro passo foi a definição da classe de dataset, que utiliza a base de\n",
    "dados Nsynth, assim como os autores do paper original: https://magenta.tensorflow.org/datasets/nsynth\n",
    "\n",
    "É necessário baixar os arquivos json/wav e descompactar para execução deste código.\n",
    "\n",
    "A classe construída é definida abaixo e utiliza o framework PyTorch."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class NsynthDatasetFourier(Dataset):\n",
    "\n",
    "    def __init__(self, path=\"nsynth-train/\", noise_length=256, shuffle=True):\n",
    "        super().__init__()\n",
    "        self.noise_length = noise_length\n",
    "        self.path = path\n",
    "\n",
    "        instr_fmly_name = [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\",\n",
    "                           \"mallet\", \"organ\", \"reed\", \"string\", \"synth_lead\",\n",
    "                           \"vocal\"]\n",
    "        instr_fmly_num = range(len(instr_fmly_name))  # 11 familias\n",
    "\n",
    "        self.instr_fmly_dict = dict(zip(instr_fmly_name, instr_fmly_num))\n",
    "\n",
    "        notas_nomes = [\"do\", \"do_s\", \"re\", \"re_s\", \"mi\", \"fa\", \"fa_s\", \"sol\",\n",
    "                       \"sol_s\", \"la\", \"la_s\", \"si\"]\n",
    "        self.notas_indices = range(len(notas_nomes))  # 12 seminotas\n",
    "\n",
    "        self.notas_dict = dict(zip(notas_nomes, self.notas_indices))\n",
    "\n",
    "        with open(os.path.join(path, 'examples.json'), 'r') as file:\n",
    "            summary_dict = json.load(file)\n",
    "\n",
    "        self.summary_df = pd.DataFrame(list(summary_dict.values()))\n",
    "        # self.summary_df = pd.get_dummies(self.summary_df, columns=[\"instrument_family_str\", ])\n",
    "\n",
    "        self.shuffle_array = torch.arange(self.summary_df.shape[0])\n",
    "        if shuffle is True: self.shuffle_array = torch.randperm(self.summary_df.shape[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.shuffle_array[index].item()\n",
    "\n",
    "        sample_info = self.summary_df.loc[idx]\n",
    "\n",
    "        sample_audio_array = wavfile.read(os.path.join(self.path, \"audio\", sample_info[\"note_str\"]) + \".wav\")[1] / 1.0\n",
    "        # sample_audio_array = _scale_data(sample_audio_array)\n",
    "        sample_audio_array = np.pad(sample_audio_array, [(700, 700), ], mode='constant')\n",
    "\n",
    "        f, t, espectro = signal.stft(x=sample_audio_array, fs=2048, nperseg=2048, noverlap=3 * 2048 // 4, padded=False)\n",
    "\n",
    "        # Jogamos fora a frequencia de Nyquist\n",
    "        espectro = espectro[:-1]\n",
    "        f = f[:-1]\n",
    "\n",
    "        # # Visualizar o espectro gerado\n",
    "        # plt.pcolormesh(t, f, np.abs(espectro), vmin=0, vmax=1e5, shading='gouraud')\n",
    "        # plt.show()\n",
    "\n",
    "        instr_fmly_one_hot = torch.zeros(((len(self.instr_fmly_dict.keys()),) + espectro.shape))\n",
    "        notas_one_hot = torch.zeros(((len(self.notas_indices),) + espectro.shape))\n",
    "\n",
    "        # Decompoe o espectro em magnitude e fase (angulo).\n",
    "        amplitude_espectro = np.abs(espectro)\n",
    "        amplitude_espectro[amplitude_espectro == 0] = 1e-6\n",
    "        magnitude_espectro = np.log10(amplitude_espectro)\n",
    "        phase_espectro = np.angle(espectro)\n",
    "\n",
    "        # Setamos como 1 o elemento daquela familia (one hot)\n",
    "        instr_fmly_one_hot[self.instr_fmly_dict[sample_info[\"instrument_family_str\"]]] = 1\n",
    "        # pitch dividido por 12 (qtde de notas), para transcrever em nota\n",
    "        # dentro da \"oitava\" em que aquele pitch se encontra.\n",
    "        notas_one_hot[self.notas_indices[sample_info[\"pitch\"] % len(self.notas_indices)]] = 1\n",
    "\n",
    "        return torch.normal(mean=0, std=1.0, size=(256, self.noise_length, self.noise_length)), \\\n",
    "               torch.cat((torch.tensor(magnitude_espectro[np.newaxis, ...]), torch.tensor(phase_espectro[np.newaxis, ...]),), dim=0)\n",
    "\n",
    "    def __len__(self, ):\n",
    "        return self.summary_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Funções de ativação\n",
    "\n",
    "Utilizamos a LeakyReLU como função de ativação, e definimos ela em uma instância\n",
    "sempre seguida de normalização, para maior comodidade. Camadas convolucionais\n",
    "usam batch norm, enquanto que camadas densas usam layer norm, o que parece ser\n",
    "uma tendência nos últimos tempos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class BnActivation(nn.Module):\n",
    "    def __init__(self, num_features=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=num_features, momentum=0.99),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(x)\n",
    "\n",
    "\n",
    "class LnActivation(nn.Module):\n",
    "    def __init__(self, normalized_shape=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.LayerNorm(normalized_shape=normalized_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelos\n",
    "\n",
    "Os modelos construídos são iguais aos do paper original, exceto por 1 única\n",
    "intervenção, que foi a adição de skip connections nas camadas convolucionais no\n",
    "estilo ResNet, para melhor propagação do gradiente."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Sequential, Linear, Sigmoid\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_input_channels=6, n_output_channels=7,\n",
    "                 kernel_size=7, stride=1, padding=0, dilation=1,\n",
    "                 groups=1, bias=True, padding_mode='zeros'):\n",
    "        \"\"\"\n",
    "    ResNet-like block, receives as arguments the same that PyTorch's Conv1D\n",
    "    module.\n",
    "        \"\"\"\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.feature_extractor = \\\n",
    "            Sequential(\n",
    "                nn.Conv2d(n_input_channels, n_output_channels, kernel_size,\n",
    "                          stride, kernel_size // 2 * dilation, dilation,\n",
    "                          groups, bias, padding_mode),\n",
    "                BnActivation(n_output_channels),\n",
    "                nn.Conv2d(n_output_channels, n_output_channels, kernel_size,\n",
    "                          stride, kernel_size // 2 * dilation,\n",
    "                          dilation, groups, bias, padding_mode),\n",
    "            )\n",
    "\n",
    "        self.skip_connection = \\\n",
    "            Sequential(\n",
    "                nn.Conv2d(n_input_channels, n_output_channels, 1,\n",
    "                          stride, padding, dilation, groups, bias, padding_mode)\n",
    "            )\n",
    "\n",
    "        self.activation = BnActivation(n_output_channels)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        return self.activation(self.feature_extractor(input_seq) + self.skip_connection(input_seq))\n",
    "\n",
    "\n",
    "class Generator2DUpsampled(nn.Module):\n",
    "    def __init__(self, n_input_channels=24, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_generator = Sequential(\n",
    "            nn.Conv2d(n_input_channels, 256, kernel_size=(2, 16), stride=(1, 1), dilation=(1, 1), padding=(1, 15), bias=bias), BnActivation(256),\n",
    "            ResBlock(256, 256, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(256, 256, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(256, 256, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(256, 256, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(256, 128, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(128, 64, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Upsample(scale_factor=2.0, mode='bilinear', align_corners=None),\n",
    "            ResBlock(64, 32, kernel_size=3, stride=1, dilation=1, padding=0, bias=bias),\n",
    "            nn.Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding='same', bias=bias),\n",
    "        )\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        som_2_canais = self.feature_generator(x).transpose(2, 3)\n",
    "        som_2_canais[:, 1, :, :] = self.activation(som_2_canais[:, 1, :, :]) * 3.1415926535897\n",
    "        som_2_canais[:, 0, :, :] = self.activation(som_2_canais[:, 0, :, :]) * 11.85 - 7.35\n",
    "        return som_2_canais\n",
    "\n",
    "\n",
    "class Discriminator2D(nn.Module):\n",
    "    def __init__(self, seq_length=64000, n_input_channels=24,\n",
    "                 kernel_size=7, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        n_output_channels = 256\n",
    "\n",
    "        self.feature_extractor = Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=3, dilation=2, bias=bias, ), BnActivation(32),\n",
    "            ResBlock(32, 64, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            ResBlock(64, 128, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            ResBlock(128, n_output_channels, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            ResBlock(n_output_channels, n_output_channels, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            ResBlock(n_output_channels, n_output_channels, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "            nn.AvgPool2d(2, 2),\n",
    "            ResBlock(n_output_channels, n_output_channels, kernel_size=3, stride=1, dilation=1, bias=bias),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            Linear(2560, 1024, bias=bias),\n",
    "            LnActivation(1024),\n",
    "            Linear(1024, 1, bias=bias),\n",
    "        )\n",
    "\n",
    "        self.activation = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.mlp(self.feature_extractor(x).flatten(start_dim=1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Função de Loss\n",
    "\n",
    "O paper original utiliza a BCE como Loss de treino. Porém, o PyTorch não permite\n",
    "utilizá-la durante a aceleração de treino com precisão mista, então fizemos a\n",
    "implementação manual da loss Hiperbólica, que possui características parecidas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HyperbolicLoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-6, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon + 1\n",
    "\n",
    "    def forward(self, y, y_hat):\n",
    "        return (1 / (self.epsilon - ((y - y_hat) ** 2))).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinamento em GPU\n",
    "\n",
    "Definimos abaixo o dispositivo de treinamento como GPU, quando disponível."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "    print(\"Usando GPU\")\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "    print(\"Usando CPU\")\n",
    "device = torch.device(dev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LR - get and set\n",
    "\n",
    "Funçãoes utilitárias para definir e verificar o learning rate de um modelo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "def set_lr(optimizer, new_lr=0.01):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tenho um pacote em python com algumas funções e classes de uso recorrente. Uma\n",
    "delas é o DataManager, uma classe que converte o dispositivo e tipo dos tensores\n",
    "em uma thread separada do código, deixando o script mais organizado e mais rápido."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install my utilities\n",
    "!pip install ptk-patrickctrf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parâmetros de treino\n",
    "\n",
    "Abaixo definimos alguns parâmetros relativos ao treino, como tamanho do mini-batch."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ptk.utils import DataManager\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "batch_size = 32\n",
    "noise_length = 1\n",
    "target_length = 128\n",
    "use_amp = True\n",
    "max_examples = 1_000_000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instanciamos nossos modelos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Models\n",
    "generator = Generator2DUpsampled(n_input_channels=256)\n",
    "discriminator = Discriminator2D(seq_length=target_length, n_input_channels=2, kernel_size=7, stride=1, padding=0, dilation=1, bias=True)\n",
    "\n",
    "# Put in GPU (if available)\n",
    "generator.to(device)\n",
    "discriminator.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selecionamos os tipos de gradiente que utilizaremos (Adam, o mais comum).\n",
    "\n",
    "Definimos também um calendário de LR, de forma que o learning rate vá\n",
    "diminuindo gradativamente ao longo do treino e permita uma otimização mais fina."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=8e-4, )\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=8e-4, )\n",
    "generator_scaler = GradScaler()\n",
    "discriminator_scaler = GradScaler()\n",
    "\n",
    "# Variable LR\n",
    "generator_scheduler = torch.optim.lr_scheduler.LambdaLR(generator_optimizer, lambda epoch: max(1 - epoch / 30000.0, 0.1))\n",
    "discriminator_scheduler = torch.optim.lr_scheduler.LambdaLR(discriminator_optimizer, lambda epoch: max(1 - epoch / 30000.0, 0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instanciamos a função de Loss."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = HyperbolicLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abrimos o dataset. LEMBRE-SE de mudar o caminho do dataset para a pasta do seu\n",
    "computador onde você o extraiu."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Data\n",
    "train_dataset = NsynthDatasetFourier(path=\"<NSYNTH-PATH-HERE>/nsynth-train/\", noise_length=noise_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo temos o loop de treinamento, com precisão mista e alguns logs em tela e\n",
    "em arquivo para acompanhar o progresso de treinamento."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Log data\n",
    "total_generator_loss = best_loss = 9999.0\n",
    "f = open(\"loss_log.csv\", \"w\")\n",
    "w = csv.writer(f)\n",
    "w.writerow([\"epoch\", \"training_loss\"])\n",
    "tqdm_bar_epoch = tqdm(range(max_examples))\n",
    "tqdm_bar_epoch.set_description(\"epoch: 0. \")\n",
    "last_checkpoint = 0\n",
    "\n",
    "n_examples = 0\n",
    "while n_examples < max_examples:\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Facilita e acelera a transferência de dispositivos (Cpu/GPU)\n",
    "    train_datamanager = DataManager(train_dataloader, device=device, buffer_size=3)\n",
    "    for x_train, y_train in train_datamanager:\n",
    "        # Comodidade para dizer que as saidas sao verdadeiras ou falsas\n",
    "        true_labels = torch.ones((x_train.shape[0], 1), device=device)\n",
    "        fake_labels = torch.zeros((x_train.shape[0], 1), device=device)\n",
    "\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        with autocast(enabled=use_amp):\n",
    "            generated_data = generator(x_train)\n",
    "\n",
    "            # Train the generator\n",
    "            # We invert the labels here and don't train the discriminator because we want the generator\n",
    "            # to make things the discriminator classifies as true.\n",
    "            generator_discriminator_out = discriminator(generated_data)\n",
    "            generator_loss = criterion(generator_discriminator_out, true_labels)\n",
    "\n",
    "        generator_scaler.scale(generator_loss).backward()\n",
    "        generator_scaler.step(generator_optimizer)\n",
    "        generator_scaler.update()\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        with autocast(enabled=use_amp):\n",
    "            true_discriminator_out = discriminator(y_train)\n",
    "            true_discriminator_loss = criterion(true_discriminator_out, true_labels)\n",
    "\n",
    "            # add .detach() here think about this\n",
    "            generator_discriminator_out = discriminator(generated_data.detach())\n",
    "            generator_discriminator_loss = criterion(generator_discriminator_out, fake_labels)\n",
    "\n",
    "            discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "\n",
    "        discriminator_scaler.scale(discriminator_loss).backward()\n",
    "        discriminator_scaler.step(discriminator_optimizer)\n",
    "        discriminator_scaler.update()\n",
    "\n",
    "        # LR scheduler update\n",
    "        discriminator_scheduler.step()\n",
    "        generator_scheduler.step()\n",
    "\n",
    "        tqdm_bar_epoch.set_description(\n",
    "            f'current_generator_loss: {total_generator_loss:5.5f}' +\n",
    "            f'. disc_fake_err: {generator_discriminator_out.detach().mean():5.5f}' +\n",
    "            f'. disc_real_acc: {true_discriminator_out.detach().mean():5.5f}' +\n",
    "            f'. gen_lr: {get_lr(generator_optimizer):1.6f}' +\n",
    "            f'. disc_lr: {get_lr(discriminator_optimizer):1.6f}'\n",
    "        )\n",
    "        tqdm_bar_epoch.update(x_train.shape[0])\n",
    "\n",
    "        n_examples += x_train.shape[0]\n",
    "\n",
    "        w.writerow([n_examples, total_generator_loss])\n",
    "        f.flush()\n",
    "\n",
    "        total_generator_loss = 0.9 * total_generator_loss + 0.1 * generator_loss.detach().item()\n",
    "\n",
    "        # Checkpoint to best models found.\n",
    "        if n_examples > last_checkpoint + 100 * batch_size and (best_loss > total_generator_loss or total_generator_loss < 2.0):\n",
    "            # Update the new best loss.\n",
    "            best_loss = total_generator_loss\n",
    "            last_checkpoint = n_examples\n",
    "            generator.eval()\n",
    "            torch.save(generator, \"checkpoints/best_generator.pth\")\n",
    "            torch.save(generator.state_dict(), \"checkpoints/best_generator_state_dict.pth\")\n",
    "            discriminator.eval()\n",
    "            torch.save(discriminator, \"checkpoints/best_discriminator.pth\")\n",
    "            torch.save(discriminator.state_dict(), \"checkpoints/best_discriminator_state_dict.pth\")\n",
    "            print(\"\\ncheckpoint!\\n\")\n",
    "            generator.train()\n",
    "            discriminator.train()\n",
    "\n",
    "        # training is over\n",
    "        if n_examples > max_examples:\n",
    "            break\n",
    "\n",
    "    # Save everything after each epoch\n",
    "    generator.eval()\n",
    "    torch.save(generator, \"checkpoints/generator.pth\")\n",
    "    torch.save(generator.state_dict(), \"checkpoints/generator_state_dict.pth\")\n",
    "    discriminator.eval()\n",
    "    torch.save(discriminator, \"checkpoints/discriminator.pth\")\n",
    "    torch.save(discriminator.state_dict(), \"checkpoints/discriminator_state_dict.pth\")\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geração de timbres\n",
    "\n",
    "Após treinado, pode usar o código abaixo para geração sonora."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sounddevice as sd\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def polar_to_rect(amplitude, angle):\n",
    "    return amplitude * (np.cos(angle) + 1j * np.sin(angle))\n",
    "\n",
    "\n",
    "generator = torch.load(\"checkpoints/generator.pth\", map_location=torch.device(\"cpu\")).train()\n",
    "\n",
    "ruido_e_classes = torch.normal(mean=0, std=1.0, size=(256, 1)).view(1, 256, 1, 1)\n",
    "\n",
    "fourier_sintetizado = generator(ruido_e_classes)[0].detach().numpy()\n",
    "\n",
    "espectro = polar_to_rect(10 ** fourier_sintetizado[0], fourier_sintetizado[1])\n",
    "\n",
    "t, x = signal.istft(Zxx=espectro, fs=2046, nperseg=2046, noverlap=3 * 2046 // 4, )\n",
    "\n",
    "x = x.astype(np.int16)\n",
    "\n",
    "sd.play(x, samplerate=16000, blocking=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}